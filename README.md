# Документация к проекту #

Основной язык работы проекта — Python 3.7.10 

Основные используемые библиотеки для всего проекта: pandas, sklearn, pickle, matplotlib, flask-restful

Фреймворк для API: flask

Весь проект был выполнен используя облачные сервисы: Google Colaboratory и Google Cloud Shell.

## Сессия 1: ##

### “1.1 Предобработка данных и выделение значимых атрибутов”: ###

Целью данного пункта было предобработать файл “Выгрузка 9 апреля.xls”, а также выделить из него значимые атрибуты. Изначально датасет выглядел следующим образом:

![image](https://user-images.githubusercontent.com/90154302/155878919-390d65c2-ce45-4070-8f2d-57ac6258e258.png)

На определение адресата и последующее обучение модели никак не повлияют столбцы "№ п/п" и "Исх. №", поэтому было принято решение их удалить: 

![image](https://user-images.githubusercontent.com/90154302/155879045-22af0d5e-3c65-48bb-bead-75cfc2c54288.png)

### “1.2 Разбиение сложных атрибутов”: ###

Cмыслом данного пункта было разбить все сложноконкатенационные столбцы. Такими столбцами были "Исх. №\nДата" и "Автор". Таким образом, на данном этапе датафрейм выглядел подобным образом: 

![image](https://user-images.githubusercontent.com/90154302/155879192-ca86ce30-be34-4dd8-bb68-3e3c96ecc12d.png)

### "1.3 Дополнение недостающими данными": ###

Согласно тех. заданию данного пункта, необходимо было дополнить датасет недостающими данными. Таким образом, для лучшего определения адресата и автора, я добавил столбец "Должность автора", содержание которого было строго определено: 0 — частная организация, 1 — гос. организация. 

### "1.4 Формирование словарей данных": ###

В ходе выполнения данного пункта я сформировал 5 новых атрибутов по контенту столбца "Краткое\nсодержание": "Письма о Ворлдскиллсе","Письма о замене","Письма о переносе","Письма о возврате","Письма об отказе":

![image](https://user-images.githubusercontent.com/90154302/155879455-eab3cfbb-47ba-4b7e-8e0e-5d1ac150cc92.png)

### "1.5 Преобразование списков переадресаций": ###

В рамках этого пункта тз для дальнейшей разработки я написал функцию, определяющую присутствует ли в столбце "Примечание" переадресация и при положительном значении - заменяет значение в столбце "Автор" на значение переадресации из "Примечание".

### "1.6 Подготовка отчета": ###

В результате всей сессии я сформировал отчет в виде комментариев к коду для все вышеперечисленных пунктов.

## Сессия 2: ##

### "2.1 Классификация документов": ###

Эта часть тз предполагает начала построения модели машинного обучения, а именно — разбиение данных на обучающую и тестовую выборки для дальнейшего успешного обучения. Разделение данных на тестовую и обучающую выборки провел при помощи train_test_split где 25% процентов отвел на тестовую часть: 

![image](https://user-images.githubusercontent.com/90154302/155879736-ad25dc65-28a0-4cb8-bdce-6d1d994c9402.png)

### "2.2 Визуализация зависимостей данных": ###

В качестве способа визуализации данных выбрал облако слов Wordcloud, где показал зависимость слов в кратком содержании от их отправителя. Результаты расчетов, а также интерпретаций на скриншоте:

![image](https://user-images.githubusercontent.com/90154302/155879772-3d5d1f1f-81c0-4ecb-aec6-84416fc6a550.png)

### "2.3 Подготовка отчета": ###

В результате всей сессии я сформировал отчет в виде комментариев к коду для все вышеперечисленных пунктов. Итоговой моделью для работы выбрал машину опорных векторов, так как у этого метода больший F-11 score, а также меньшее время обучения. Как способ визуализации зависимостей данных друг от друга выбрал Облако слов, потому что такой подход позволяет с наименьшими затратами лицезреть наибольшее кол-во данных и зависимостей их друг от друга. В результате визуализации ~самый часто встречаемым словом в "Краткое\nсодержание" стало "Министерство", а самым часто встречаемым отправителем стал "Глушко". Тестовую сборку поделил на 25% тестовой и 75 % обучающей для эффективнейшего подхода при обучении. Далее обученные модели показали, что в разбиение данных я не ошибся.

## Сессия 3: ##

### "3.1 Обучение": ###

В данном пункте проводилось обучение нескольких моделей классификации, тест моделей на обучающей и тестовой выборках данных, а также сравнение показателей их точности.

![image](https://user-images.githubusercontent.com/90154302/155880197-fca6c24b-a4b1-4ebd-a404-be8616c46938.png)

![image](https://user-images.githubusercontent.com/90154302/155880207-c119c803-c373-4f59-afdc-6c1ff604adb5.png)

![image](https://user-images.githubusercontent.com/90154302/155880212-02fa2d60-8c08-442a-9320-de2db02362af.png)

![image](https://user-images.githubusercontent.com/90154302/155880220-231192c1-2293-424d-86a5-35fc3290967b.png)

Среди всех протестированных моделей на основе обучающей выборки, лучшей себя показала модель машины опорных данных

![image](https://user-images.githubusercontent.com/90154302/155880255-5ad472ec-4622-4e1e-ad15-3ca8046df481.png)

![image](https://user-images.githubusercontent.com/90154302/155880263-f644d8cd-d01d-40b9-b14b-4028968d3ab8.png)

![image](https://user-images.githubusercontent.com/90154302/155880271-1484e44f-0dd7-48e5-90b8-b395d17c3286.png)

![image](https://user-images.githubusercontent.com/90154302/155880281-3af345a2-3df3-42ff-afff-943884879aa3.png)

Среди всех протестированных моделей на основе тестовой выборки, лучшей себя показала модель машины опорных данных, поэтому было принято решение продолжить далее с ней.

### "3.2 FeatureEngineering": ###

Здесь нашей задачей было улучшить показатели модели классификации путем преобразования набора данных. Методом преобразования данных я выбрал Векторизацию CountVectorizer, так как такой метод я посчитал самым эффективным для наших данных, состоящих из строковых значений: 

![image](https://user-images.githubusercontent.com/90154302/155880443-d9e202ec-78ad-4105-96d5-5b047fb3dd4a.png)

Ход обучения модели на разных данных и FeatureEngineering:

![image](https://user-images.githubusercontent.com/90154302/155882678-3a2b03db-e78f-4386-9267-202f18eb1412.png)

![image](https://user-images.githubusercontent.com/90154302/155882687-f34c86e9-9852-4a8f-b5e3-93a2efb79177.png)

![image](https://user-images.githubusercontent.com/90154302/155882647-7a5cc6f4-de24-4f1f-8254-fcfefe89ca4f.png)

Такой подход, а также смена диапазона обучения с "Место работы автора-Адресат" на "Краткое содержание-Адресат" привело к увеличению точности модели. Точность модели "Машина опорных векторов" по обучающей выборке "Место работы автора-Адресат" по F1(1) составляла ~56.038647342995176%, но после Feature Engineering точность модели стала составлять ~66.50563607085346%

### "3.3Подготовка отчета": ###

В результате всей сессии я сформировал отчет в виде комментариев к коду для все вышеперечисленных пунктов. Путем тестирования и сравнения с другими моделями, выбрал модель обучения — машина опорных векторов, так как такая модель дает наибольший показатель точности. Модель показала себя лучше при наборе данных "Краткое\nсодержание-Адресат". FeatureEngineering привело к увеличению точности более чем на 10% по F1(1).

## Сессия 4: ##

### "4.1 Разработка бота": ###

В этой части наступил разработческая часть. Первостепенной задачей стало написание бота. Функции бота были следующие: По введенным параметрам выполнять команды определения адресата по описанию входного документа, выдачи документов за определенный период по заданному адресату, распознавать команды, описанные на естественном языке, предоставлять справку по имеющимся командам и их параметрам. За команду определения адресата по введенному краткому содержанию отвечает "/determine_addres", за команду определения краткого содержания по введенному адресату отвечает "/documents_date_by_addres", за вывод справки по имеющимся командам и их параметрам отвечает "/help". Структура бота:

![image](https://user-images.githubusercontent.com/90154302/155880788-14d89ebf-44b2-4c41-9cbf-23a5677875ae.png)

### "4.2 Настройки бота": ###

В данном пункте необходимо было разработать параметры жесткости определения адресата так, чтобы пользователь мог сам выбирать: показать ему одного конкретного адресата или нескольких более вероятных.

### "4.3Подготовка руководства пользователя": ###

Руководство пользователя к боту:
Интерфейс бота — командная строка. 
Обращение к боту происходит только путем команд в командной консоли. 
Чтобы получить список команд и их объяснения воспользуйтесь командой /help. 
Бот ограничен тремя командами: вывод справки по командам, вывод краткого содержания письма по введённому адресату и вывод определённого адресата по краткому содержанию письма.
Бот не отреагирует ни на какой символ кроме команды. 
Актуальные команды: 
/documents_date_by_addres (позволяет получить краткое содержание письма по введенному адресату)
/help (выводит справку по имеющимся командам и их параметрам) 
/determine_addres (позволяет определить адресата по краткому описанию входного документа)

## Сессия 5: ##

### "5.1 Разработка API": ###

Данный пункт был отведен под разработку рабочего API интерфейса. Интерфейс предоставляет метод, принимающий в качестве параметров данные, а в качестве результата возвращается структура с заполненным значением атрибута "Адресат". Структура API вышла следующая:

![image](https://user-images.githubusercontent.com/90154302/155881208-6d7083fc-2530-4a10-938a-97e77c64454d.png)

### "5.2 Последующее обучение": ###

Тут необходимо было внести опцию оценки корректности результата. Если оператор системы считает, что адресат определен неправильно, он вносит изменения. При каждой такой ситуации дополняется набор данных, который в перспективе будет использоваться для обучения модели.

### "5.3Программная документация": ###

Документация пользователя к API “API”:

— В API находится 2 файла: “SuperDuperModel.sav” и “session11.py”

— В API содержится файл “session11.py” с содержанием двух моделей обучения 

— При работе с API стоит учитывать, что код написан на Python, Flask и др. 

ВАЖНО!: Отсутствует Web-интерфейс

— API предназначен для работы в консоли, вывод работы API в http: недопустим

— API полостью позволяет работать с ботом, написанным ранее 

— Все функции бота в API сохранены 

— Запускать API и дальше работать с ней следует только в Google Cloud Shell

— Чтобы начать работу API запустите файл “session11.py” и следуйте документации пользователя к боту, написанному ранее 

— Пример полного запроса для API: 

![image](https://user-images.githubusercontent.com/90154302/155881336-33346ebd-61c2-48ea-96e1-299add9dbba1.png)

— Пример полного вывода для API:

![image](https://user-images.githubusercontent.com/90154302/155881342-89de596d-23b7-466d-bf39-5d9dd889754e.png)

Предупреждение: в скором времени будут происходить апдейты API и самого проекта, поэтому данная версия будет устаревать, следите за обновлениями.
